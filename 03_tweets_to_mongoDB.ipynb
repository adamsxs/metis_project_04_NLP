{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing Twitter API and Storing Tweets in MongoDB\n",
    "\n",
    "We can access the Twitter API using the `requests` library or through `tweepy`, and then store the tweets locally on a MongoDB database. [Click here for Twitter Search API documentation.](https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets.html)\n",
    "\n",
    "Large swaths of this notebook are directly from notebooks found in the Metis 2018 Chicago Winter cohort, and adapted as needed for my project.  \n",
    "\n",
    "I've queried tweets relating to [Matthew Berry](https://en.wikipedia.org/wiki/Matthew_Berry), an ESPN Fantasy Sports analyst and column writer who I've followed for several years while playing fantasy football. His [\"Love/Hate\" column](http://www.espn.com/fantasy/football/story/_/page/TMRlovehate181115/fantasy-football-picks-sleepers-busts-week-11) airs every Thursday. Once a year, he unblocks people on social media who make a donation to the [Jimmy V Foundation](https://www.jimmyv.org), and it's always had me wondering how nasty people will get on Twitter over fantasy football."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# This is needed to authenticate us to Twitter\n",
    "\n",
    "try:\n",
    "    from requests_oauthlib import OAuth1\n",
    "except ModuleNotFoundError:\n",
    "    import sys\n",
    "    import os\n",
    "\n",
    "    # I need this because requests_oauth gets installed in a weird place on my system\n",
    "    sys.path.append('/usr/local/lib/python3.6/site-packages')\n",
    "    from requests_oauthlib import OAuth1\n",
    "\n",
    "# Loading Twitter API access tokens and keys\n",
    "from twitter_credentials import credentials\n",
    "import tweepy\n",
    "\n",
    "# MongoDB\n",
    "import json\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTweet(tweet):\n",
    "    tweet_dict = {\n",
    "        'id': tweet.id_str,\n",
    "        'datetime': tweet.created_at,\n",
    "        'tweet': tweet.full_text,\n",
    "        'entities': tweet.entities,\n",
    "        # The following stores a user object\n",
    "        'user': tweet.user._json\n",
    "    }\n",
    "    \n",
    "    if tweet.coordinates:\n",
    "        tweet_dict['coordinates'] = tweet.coordinates\n",
    "    if tweet.geo:\n",
    "        tweet_dict['geo'] = tweet.geo\n",
    "    \n",
    "    return tweet_dict\n",
    "\n",
    "def query_twitter(api, query_params, n_queries):\n",
    "    '''\n",
    "    Query twitter search api and return list of desired tweet components\n",
    "    as a list of dictionaries.\n",
    "    Handles exceptions from Twitter's 429 error code for too many queries.\n",
    "    ---\n",
    "    Inputs:\n",
    "        api: Tweepy API object instance. Should already be authenticated.\n",
    "        query_params: Twitter API query parameters\n",
    "    Returns:\n",
    "        tweets: list[dict()], each dict is a processed tweet.\n",
    "    '''\n",
    "    # Create cursor object to look through tweets\n",
    "    cursor = tweepy.Cursor(api.search, **query_params).items(n_queries)\n",
    "    \n",
    "    tweets = []\n",
    "    # Use try clause to preserve previously processed tweets in the event \n",
    "    # of a an error, usually TweepError: Twitter error response: status code = 429\n",
    "    try:\n",
    "        for tweet in cursor:\n",
    "            # Retrieve selected fields from tweet\n",
    "            tweets.append(processTweet(tweet))\n",
    "    except:\n",
    "        print('Exiting `try` loop because of error.')\n",
    "    else:\n",
    "        print('Completed query without errors.')\n",
    "    finally:\n",
    "        print('Retrieved {} tweets.'.format(len(tweets)))\n",
    "    \n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic takeway\n",
    "- requests.get(url): make a (GET) request to a URL. Can get a webpage or a JSON object back. Returns a `response` object\n",
    "- `response.json()` access the JSON object returned (if there was one)\n",
    "\n",
    "To get this to work with Twitter, we will need to authenticate ourselves. This is the job of OAuth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "oauth = OAuth1(credentials[\"TWITTER_CONSUMER_KEY\"],\n",
    "               credentials[\"TWITTER_CONSUMER_KEY_SECRET\"],\n",
    "               credentials[\"TWITTER_ACCESS_TOKEN\"],\n",
    "               credentials[\"TWITTER_ACCESS_TOKEN_SECRET\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter search API (free version scrapes last week's tweets)\n",
    "\n",
    "A detailed description of the twitter search API can be found [here](https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets.html). Some of the key parameters\n",
    "\n",
    "| Parameter | Notes | Example |\n",
    "|---|---|---|\n",
    "| q | (required) query string to search for | `@metis` |\n",
    "| geocode | (optional) Uses tweet geolocation, or user's profile location if tweet geolocation disabled. Should be of the format `latitude longitude radius[unit]` where unit is either \"km\" or \"mi\" | `41.8781, -87.6298, 5mi` |\n",
    "| lang | (optional) Only return tweets in language given. Languages are coded by the two character code used in [ISO 639-1](http://en.wikipedia.org/wiki/List_of_ISO_639-1_codes). | `en` `es` |\n",
    "| count | (optional) Number of results to return. Defaults to 15, max value is 100 | `20` |\n",
    "\n",
    "The API returns a JSON object with two keys:\n",
    "- search_metadata: Information about how long the search took, what was searched for, etc\n",
    "- statuses: the actual queries that you wanted\n",
    "\n",
    "Let's see it in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"q\": \"@MatthewBerryTMR\", \n",
    "              \"count\":1000, \n",
    "             \"lang\":\"en\",\n",
    "            \"include_entities\":\"True\",\n",
    "              \"tweet_mode\":\"extended\"\n",
    "             }\n",
    "\n",
    "response = requests.get(\"https://api.twitter.com/1.1/search/tweets.json\",\n",
    "                        params = parameters,\n",
    "                        auth=oauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('RT @MatthewBerryTMR: Fantasy heartbreak as a long TD run by David Johnson is '\n",
      " 'called back by a holding penalty on Ricky Seals-Jones')\n"
     ]
    }
   ],
   "source": [
    "# Just look at the first tweet text\n",
    "pprint.pprint(response.json()['statuses'][1]['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets =  100\n"
     ]
    }
   ],
   "source": [
    "# Check number of tweets in the response JSON\n",
    "print(\"Number of tweets = \", len(tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pull the next set of tweets using the query's metadata. We're looking for the extended text of a tweet rather than the truncated version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@MatthewBerryTMR Ingram is really being a vulture today ðŸ’”ðŸ’” #IHaveKamara\n",
      "\n",
      "RT @MatthewBerryTMR: Crazy https://t.co/GRnpDLCsi5\n",
      "\n",
      "RT @MatthewBerryTMR: Crazy https://t.co/GRnpDLCsi5\n",
      "\n",
      "RT @MatthewBerryTMR: Crazy https://t.co/GRnpDLCsi5\n",
      "\n",
      "RT @MatthewBerryTMR: Crazy https://t.co/GRnpDLCsi5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "next_page_url = \"https://api.twitter.com/1.1/search/tweets.json\" + response.json()['search_metadata']['next_results']\\\n",
    "+'&tweet_mode=extended'\n",
    "\n",
    "response = requests.get(next_page_url, auth=oauth)\n",
    "\n",
    "more_tweets = response.json()['statuses']\n",
    "\n",
    "for tweet in more_tweets[:5]:\n",
    "    print(tweet['full_text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull tweets into Mongo DB\n",
    "\n",
    "Using `mongoclient` we can load in credentials and use the cursor object to scroll through the search results. Unlike the JSON style object we have from requests, we can use dot '`.`' calls to the JSON keys to get information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load twitter credentials from local file\n",
    "auth = tweepy.OAuthHandler(credentials[\"TWITTER_CONSUMER_KEY\"],\n",
    "                           credentials[\"TWITTER_CONSUMER_KEY_SECRET\"])\n",
    "auth.set_access_token(credentials[\"TWITTER_ACCESS_TOKEN\"],\n",
    "                      credentials[\"TWITTER_ACCESS_TOKEN_SECRET\"])\n",
    "\n",
    "api=tweepy.API(auth)\n",
    "\n",
    "# Using local mongo client after we activate the mongod Daemon in Terminal\n",
    "client = MongoClient()\n",
    "db = client.berry_tweets #database structure is the overhead needed to hold collections of documents\n",
    "twt_cl = db.tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admin', 'berry_tweets', 'config', 'legistlation', 'local', 'my_new_db']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View active databases\n",
    "client.database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting `try` loop because of error.\n",
      "Retrieved 2620 tweets.\n"
     ]
    }
   ],
   "source": [
    "# Query twitter search API until rate limits kick in. Grab as many tweets as possible.\n",
    "params = {\n",
    "    'q':'@MatthewBerryTMR',\n",
    "    'tweet_mode':'extended',\n",
    "    'lang':'en',\n",
    "    'include_entities':True\n",
    "}\n",
    "n_tweets = 2800\n",
    "query_results = query_twitter(api,params,n_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the PyMongo client to store some information in the database.\n",
    "Eventually look at using `twt_cl.create_index()` command to give all tweets a unique index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 0 Duplicates in new query: 0.0\n",
      "New entries: 2620\n",
      "Database size: 9116\n"
     ]
    }
   ],
   "source": [
    "# Take a list of processed tweets from a query and insert unique ones into the database\n",
    "\n",
    "already_in = 0\n",
    "collection_count_initial = twt_cl.count()\n",
    "for tweet in too_many_tweets:\n",
    "    if twt_cl.find({'id':tweet['id']}).count() >0:\n",
    "        already_in += 1\n",
    "    elif twt_cl.find({'id':tweet['id']}).count() ==0:\n",
    "        twt_cl.insert_one(tweet)\n",
    "    else:\n",
    "        print(\"unexpected\")\n",
    "\n",
    "print('Duplicates: {0} Duplicates in new query: {1}'.format(already_in, already_in/len(too_many_tweets)))\n",
    "print('New entries: {}'.format(twt_cl.count()-collection_count_initial))\n",
    "print('Database size: {}'.format(twt_cl.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9116"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many documents do we have\n",
    "twt_cl.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9051"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many mention Matthew Berry?\n",
    "twt_cl.find({\"tweet\": {\"$regex\": \"@MatthewBerryTMR\"}}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
