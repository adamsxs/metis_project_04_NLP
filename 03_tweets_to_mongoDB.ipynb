{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter and Python\n",
    "\n",
    "We will be showing how to access Twitter using Python. We will use\n",
    "1. the relatively low-level `requests` library, which will deal with any API\n",
    "2. the easier to use tweety library, but which only works with Twitter\n",
    "\n",
    "We will need to install some packages. From inside the directory with the file, run\n",
    "```bash\n",
    "conda install -c conda-forga --file requirements.txt\n",
    "```\n",
    "or \n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "[Click here for Twitter Search API documentation.](https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import pandas as pd\n",
    "import requests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The requests library\n",
    "\n",
    "We will be doing a lot of work with Twitter, but I don't want you to leave with the impresssion that requests only works with Twitter. It works with any API, and we have already used it with our Flask apps. A request is a \"low-level\" network call, and duplicates what the command line tool curl does, for example.\n",
    "\n",
    "Before diving into connecting to Twitter (where we will need to provide a username and password), I wanted to give an example using the [Star Wars API](http://swapi.co) which doesn't require authentication. \n",
    "\n",
    "Let's start with curl from the command line (the `json_pp` just makes the output JSON pretty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic takeway\n",
    "- requests.get(url): make a (GET) request to a URL. Can get a webpage or a JSON object back. Returns a `response` object\n",
    "- `response.json()` access the JSON object returned (if there was one)\n",
    "\n",
    "To get this to work with Twitter, we will need to authenticate ourselves. This is the job of OAuth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions to connect to Twitter using requests\n",
    "\n",
    "We need to identify ourselves to Twitter using \n",
    "- a public and private key, which doesn't expire\n",
    "- as well as a public and private token (which does expire). \n",
    "If you are re-running this notebook tomorrow, you will need to get a token from the Twitter page (but your keys will remain the same).\n",
    "\n",
    "Follow the instructions [here](setup_twitter_instructions.md) to get your keys and tokens, and place them in `twitter_credenitials.py`.\n",
    "\n",
    "**The cell below won't work until you follow the instructions!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed to authenticate us to Twitter\n",
    "\n",
    "try:\n",
    "    from requests_oauthlib import OAuth1\n",
    "except ModuleNotFoundError:\n",
    "    import sys\n",
    "    import os\n",
    "\n",
    "    # I need this because requests_oauth gets installed in a weird place on my system\n",
    "    sys.path.append('/usr/local/lib/python3.6/site-packages')\n",
    "    from requests_oauthlib import OAuth1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twitter_credentials import credentials\n",
    "\n",
    "oauth = OAuth1(credentials[\"TWITTER_CONSUMER_KEY\"],\n",
    "               credentials[\"TWITTER_CONSUMER_KEY_SECRET\"],\n",
    "               credentials[\"TWITTER_ACCESS_TOKEN\"],\n",
    "               credentials[\"TWITTER_ACCESS_TOKEN_SECRET\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter search API (free version scrapes last week's tweets)\n",
    "\n",
    "A detailed description of the twitter search API can be found [here](https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets.html). Some of the key parameters\n",
    "\n",
    "| Parameter | Notes | Example |\n",
    "|---|---|---|\n",
    "| q | (required) query string to search for | `@metis` |\n",
    "| geocode | (optional) Uses tweet geolocation, or user's profile location if tweet geolocation disabled. Should be of the format `latitude longitude radius[unit]` where unit is either \"km\" or \"mi\" | `41.8781, -87.6298, 5mi` |\n",
    "| lang | (optional) Only return tweets in language given. Languages are coded by the two character code used in [ISO 639-1](http://en.wikipedia.org/wiki/List_of_ISO_639-1_codes). | `en` `es` |\n",
    "| count | (optional) Number of results to return. Defaults to 15, max value is 100 | `20` |\n",
    "\n",
    "The API returns a JSON object with two keys:\n",
    "- search_metadata: Information about how long the search took, what was searched for, etc\n",
    "- statuses: the actual queries that you wanted\n",
    "\n",
    "Let's see it in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"q\": \"@MatthewBerryTMR\", \n",
    "              \"count\":1000, \n",
    "              #\"geocode\": \"41.8781,-87.6298,10mi\",\n",
    "             \"lang\":\"en\",\n",
    "            \"include_entities\":\"True\",\n",
    "              \"tweet_mode\":\"extended\"\n",
    "             }\n",
    "\n",
    "response = requests.get(\"https://api.twitter.com/1.1/search/tweets.json\",\n",
    "                        params = parameters,\n",
    "                        auth=oauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contributors': None,\n",
      " 'coordinates': None,\n",
      " 'created_at': 'Tue Nov 13 21:36:53 +0000 2018',\n",
      " 'display_text_range': [17, 76],\n",
      " 'entities': {'hashtags': [],\n",
      "              'symbols': [],\n",
      "              'urls': [],\n",
      "              'user_mentions': [{'id': 20899023,\n",
      "                                 'id_str': '20899023',\n",
      "                                 'indices': [0, 16],\n",
      "                                 'name': 'Matthew Berry',\n",
      "                                 'screen_name': 'MatthewBerryTMR'}]},\n",
      " 'favorite_count': 1,\n",
      " 'favorited': False,\n",
      " 'full_text': '@MatthewBerryTMR Unless they drafted Connor in the handcuff '\n",
      "              'like this guy üëçüëç',\n",
      " 'geo': None,\n",
      " 'id': 1062459307080515584,\n",
      " 'id_str': '1062459307080515584',\n",
      " 'in_reply_to_screen_name': 'MatthewBerryTMR',\n",
      " 'in_reply_to_status_id': 1062448993383387146,\n",
      " 'in_reply_to_status_id_str': '1062448993383387146',\n",
      " 'in_reply_to_user_id': 20899023,\n",
      " 'in_reply_to_user_id_str': '20899023',\n",
      " 'is_quote_status': False,\n",
      " 'lang': 'en',\n",
      " 'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
      " 'place': None,\n",
      " 'retweet_count': 0,\n",
      " 'retweeted': False,\n",
      " 'source': '<a href=\"http://twitter.com/download/iphone\" '\n",
      "           'rel=\"nofollow\">Twitter for iPhone</a>',\n",
      " 'truncated': False,\n",
      " 'user': {'contributors_enabled': False,\n",
      "          'created_at': 'Fri Jul 08 21:24:53 +0000 2011',\n",
      "          'default_profile': True,\n",
      "          'default_profile_image': False,\n",
      "          'description': '',\n",
      "          'entities': {'description': {'urls': []}},\n",
      "          'favourites_count': 49,\n",
      "          'follow_request_sent': False,\n",
      "          'followers_count': 29,\n",
      "          'following': False,\n",
      "          'friends_count': 233,\n",
      "          'geo_enabled': True,\n",
      "          'has_extended_profile': False,\n",
      "          'id': 331878127,\n",
      "          'id_str': '331878127',\n",
      "          'is_translation_enabled': False,\n",
      "          'is_translator': False,\n",
      "          'lang': 'en',\n",
      "          'listed_count': 0,\n",
      "          'location': '',\n",
      "          'name': 'Greg Magnusen',\n",
      "          'notifications': False,\n",
      "          'profile_background_color': 'C0DEED',\n",
      "          'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
      "          'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
      "          'profile_background_tile': False,\n",
      "          'profile_banner_url': 'https://pbs.twimg.com/profile_banners/331878127/1412335260',\n",
      "          'profile_image_url': 'http://pbs.twimg.com/profile_images/2921149462/58671ad154b75f08d7c29d8af144f2ff_normal.jpeg',\n",
      "          'profile_image_url_https': 'https://pbs.twimg.com/profile_images/2921149462/58671ad154b75f08d7c29d8af144f2ff_normal.jpeg',\n",
      "          'profile_link_color': '1DA1F2',\n",
      "          'profile_sidebar_border_color': 'C0DEED',\n",
      "          'profile_sidebar_fill_color': 'DDEEF6',\n",
      "          'profile_text_color': '333333',\n",
      "          'profile_use_background_image': True,\n",
      "          'protected': False,\n",
      "          'screen_name': 'GregnotSteve',\n",
      "          'statuses_count': 164,\n",
      "          'time_zone': None,\n",
      "          'translator_type': 'none',\n",
      "          'url': None,\n",
      "          'utc_offset': None,\n",
      "          'verified': False}}\n"
     ]
    }
   ],
   "source": [
    "# Just look at the first tweet:\n",
    "pprint.pprint(response.json()['statuses'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Tweet body: @CoreyCorbin78 @kevinkerbrat @MatthewBerryTMR yes all of them lol if you believe connor is a better player than bell then there‚Äôs no point in arguing\n",
      "        Hashtags: []\n",
      "        Username: SeanOneill_NJ\n",
      "        Bio: Just sling it\n",
      "        Social status: 139 friends, 102 followers\n",
      "        Location: \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Ok, can we extract some of the info from this text?\n",
    "tweets = response.json()['statuses']\n",
    "print(tweet_to_string(tweets[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Tweet body: @CoreyCorbin78 @kevinkerbrat @MatthewBerryTMR yes all of them lol if you believe connor is a better player than bell then there‚Äôs no point in arguing\n",
      "        Hashtags: []\n",
      "        Username: SeanOneill_NJ\n",
      "        Bio: Just sling it\n",
      "        Social status: 139 friends, 102 followers\n",
      "        Location: \n",
      "    \n",
      "\n",
      "        Tweet body: RT @MatthewBerryTMR: LeVeon goes into the fantasy football record book as the worst draft pick in the history of the game. https://t.co/Nag‚Ä¶\n",
      "        Hashtags: []\n",
      "        Username: canes415\n",
      "        Bio: Canes üôåüèªHeat üî•Dolphinsüê¨\n",
      "        Social status: 643 friends, 205 followers\n",
      "        Location: Ft. Lauderdale Florida\n",
      "    \n",
      "\n",
      "        Tweet body: @MatthewBerryTMR Unless they drafted Connor in the handcuff like this guy üëçüëç\n",
      "        Hashtags: []\n",
      "        Username: GregnotSteve\n",
      "        Bio: \n",
      "        Social status: 233 friends, 29 followers\n",
      "        Location: \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for tweet in tweets[:3]:\n",
    "    print(tweet_to_string(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did we pull all 20 tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets =  100\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tweets = \", len(tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pull the next set of tweets if we want (i.e. the \"next\" 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?max_id=1062463013284929536&q=%40MatthewBerryTMR&lang=en&count=100&include_entities=1&tweet_mode=extended'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()['search_metadata']['next_results']+'&tweet_mode=extended'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@CoreyCorbin78 @kevinkerbrat @MatthewBerryTMR yes all of them lol if you believe connor is a better player than bell then there‚Äôs no point in arguing\n",
      "\n",
      "RT @MatthewBerryTMR: LeVeon goes into the fantasy football record book as the worst draft pick in the history of the game. https://t.co/Nag‚Ä¶\n",
      "\n",
      "@MatthewBerryTMR Unless they drafted Connor in the handcuff like this guy üëçüëç\n",
      "\n",
      "@DezpicableD @MatthewBerryTMR It‚Äôs possible.  It‚Äôs very unlikely.\n",
      "\n",
      "@MatthewBerryTMR Guilty as charged\n",
      "\n"
     ]
    }
   ],
   "source": [
    "next_page_url = \"https://api.twitter.com/1.1/search/tweets.json\" + response.json()['search_metadata']['next_results']\\\n",
    "+'&tweet_mode=extended'\n",
    "\n",
    "response = requests.get(next_page_url, auth=oauth)\n",
    "\n",
    "more_tweets = response.json()['statuses']\n",
    "\n",
    "for tweet in more_tweets[:5]:\n",
    "    print(tweet['full_text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Nicholasgee33 @LeVeonBell @MatthewBerryTMR I'm hoping bell comes back though cuz I think my team would be unstoppable\n",
      "\n",
      "@tg_716 @MatthewBerryTMR I think he probably does feel bad for all the other people who ‚Äúget the shaft.‚Äù That‚Äôs cal‚Ä¶ https://t.co/Yr56XB2ejP\n",
      "\n",
      "@Nicholasgee33 @LeVeonBell @MatthewBerryTMR What??\n",
      "\n",
      "@Nicholasgee33 @LeVeonBell @MatthewBerryTMR Why would u do that lol I drafted both but also had Rodgers so I traded‚Ä¶ https://t.co/nkpraNbf7r\n",
      "\n",
      "RT @MatthewBerryTMR: In Week 4, Mitchell Trubisky threw 6 touchdown passes. Okay. That‚Äôs a fluke, right? TB is brutal. Forget that. Here‚Äôs‚Ä¶\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(next_page_url, auth=oauth)\n",
    "\n",
    "more_tweets = response.json()['statuses']\n",
    "\n",
    "for tweet in more_tweets[:5]:\n",
    "    print(tweet['text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming tweets\n",
    "\n",
    "Instead of looking at the tweets that have already been made, we can look at the tweets in real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "auth = tweepy.OAuthHandler(credentials[\"TWITTER_CONSUMER_KEY\"],\n",
    "                           credentials[\"TWITTER_CONSUMER_KEY_SECRET\"])\n",
    "auth.set_access_token(credentials[\"TWITTER_ACCESS_TOKEN\"],\n",
    "                      credentials[\"TWITTER_ACCESS_TOKEN_SECRET\"])\n",
    "\n",
    "api=tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Daniel_Penrod11 says: @MatthewBerryTMR I have Alex Collins and John Brown. Only starting Collins for now, but really want to roll the dice on Smokey\n",
      "\n",
      "1. mike__patton77 says: @Beav04 @WilAnthropist @MatthewBerryTMR You realize he‚Äôs only missed like 3 kicks all season right.\n",
      "\n",
      "2. k_bender23 says: RT @MatthewBerryTMR: LeVeon goes into the fantasy football record book as the worst draft pick in the history of the game. https://t.co/Nag‚Ä¶\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_tweets = 3\n",
    "\n",
    "test_q_params = {\n",
    "    'q':\"@MatthewBerryTMR\",\n",
    "    'tweet_mode':'extended',\n",
    "    'lang':'en'\n",
    "}\n",
    "\n",
    "for index, tweet in enumerate(tweepy.Cursor(api.search, **test_q_params).items(max_tweets)):\n",
    "    # You can see all the methods available on tweet using .<tab> or \n",
    "    # dir(tweet). You can access the raw JSON using tweet._json\n",
    "    print(str(index) + '. ' + tweet.user.screen_name + \" says: \"+ tweet.full_text + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Daniel_Penrod11 says: @MatthewBerryTMR I have Alex Collins and John Brown. Only starting Collins for now, but really want to roll the dice on Smokey\n",
      "\n",
      "1. mike__patton77 says: @Beav04 @WilAnthropist @MatthewBerryTMR You realize he‚Äôs only missed like 3 kicks all season right.\n",
      "\n",
      "2. k_bender23 says: RT @MatthewBerryTMR: LeVeon goes into the fantasy football record book as the worst draft pick in the history of the game. https://t.co/Nag‚Ä¶\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can also duplicate our original query\n",
    "\n",
    "# use ** when passing in parameters as a shortcut way to pass params in to the function as a list\n",
    "for index, tweet in enumerate(tweepy.Cursor(api.search, **test_q_params).items(max_tweets)):\n",
    "    print(str(index) + '. ' + tweet.user.screen_name + \" says: \"+ tweet.full_text + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data into Mongo\n",
    "\n",
    "We can also insert tweets into MongoDB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# If we wanted to connect to Mongo on AWS, this is where we'd set that info\n",
    "\n",
    "#uri = 'mongodb://sam:mongo_sam@18.216.212.82:27017'\n",
    "#client = MongoClient(uri)\n",
    "\n",
    "# Using local mongo client after we activate the mongod Daemon in Terminal\n",
    "client = MongoClient()\n",
    "db = client.berry_tweets #database structure is the overhead needed to hold collections of documents\n",
    "twt_cl = db.tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admin', 'berry_tweets', 'config', 'legistlation', 'local', 'my_new_db']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTweet(tweet):\n",
    "    tweet_dict = {\n",
    "        'id': tweet.id_str,\n",
    "        'datetime': tweet.created_at,\n",
    "        'tweet': tweet.full_text,\n",
    "        'entities': tweet.entities,\n",
    "        # The following stores a user object\n",
    "        'user': tweet.user._json\n",
    "    }\n",
    "    \n",
    "    if tweet.coordinates:\n",
    "        tweet_dict['coordinates'] = tweet.coordinates\n",
    "    if tweet.geo:\n",
    "        tweet_dict['geo'] = tweet.geo\n",
    "    \n",
    "    return tweet_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_twitter(api, query_params, n_queries):\n",
    "    '''\n",
    "    Query twitter search api and return list of desired tweet components\n",
    "    as a list of dictionaries.\n",
    "    Handles exceptions from Twitter's 429 error code for too many queries.\n",
    "    ---\n",
    "    Inputs:\n",
    "        api: Tweepy API object instance. Should already be authenticated.\n",
    "        query_params: Twitter API query parameters\n",
    "    Returns:\n",
    "        tweets: list[dict()], each dict is a processed tweet.\n",
    "    '''\n",
    "    # Create cursor object to look through tweets\n",
    "    cursor = tweepy.Cursor(api.search, **query_params).items(n_queries)\n",
    "    \n",
    "    tweets = []\n",
    "    # Use try clause to preserve previously processed tweets in the event \n",
    "    # of a an error, usually TweepError: Twitter error response: status code = 429\n",
    "    try:\n",
    "        for tweet in cursor:\n",
    "            # Retrieve selected fields from tweet\n",
    "            tweets.append(processTweet(tweet))\n",
    "#     except TweepError:\n",
    "#         print('Shut down by twitter api')\n",
    "    except:\n",
    "        print('Exiting `try` loop because of error.')\n",
    "    else:\n",
    "        print('Completed query without errors.')\n",
    "    finally:\n",
    "        print('Retrieved {} tweets.'.format(len(tweets)))\n",
    "    \n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed query without errors.\n",
      "Retrieved 3 tweets.\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'q':'@MatthewBerryTMR',\n",
    "    'tweet_mode':'extended',\n",
    "    'lang':'en',\n",
    "    'include_entities':True\n",
    "}\n",
    "list_of_tweets = query_twitter(api,params,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting `try` loop because of error.\n",
      "Retrieved 2699 tweets.\n"
     ]
    }
   ],
   "source": [
    "too_many_tweets = query_twitter(api,params,2800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twt_cl.create_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the PyMongo client to get some information back from the database!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 2693 Duplicates in new query: 0.9977769544275658\n",
      "New entries: 6\n",
      "Database size: 5204\n"
     ]
    }
   ],
   "source": [
    "# Take a list of processed tweets from a query and insert unique ones into the database\n",
    "\n",
    "already_in = 0\n",
    "collection_count_initial = twt_cl.count()\n",
    "for tweet in too_many_tweets:\n",
    "    if twt_cl.find({'id':tweet['id']}).count() >0:\n",
    "        already_in += 1\n",
    "    elif twt_cl.find({'id':tweet['id']}).count() ==0:\n",
    "        twt_cl.insert_one(tweet)\n",
    "    else:\n",
    "        print(\"unexpected\")\n",
    "\n",
    "print('Duplicates: {0} Duplicates in new query: {1}'.format(already_in, already_in/len(too_many_tweets)))\n",
    "print('New entries: {}'.format(twt_cl.count()-collection_count_initial))\n",
    "print('Database size: {}'.format(twt_cl.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5204"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many documents do we have\n",
    "twt_cl.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2668"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many mention Matthew Berry?\n",
    "twt_cl.find({\"tweet\": {\"$regex\": \"@MatthewBerryTMR\"}}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ohio, USA'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twt_cl.find_one({\"tweet\": {\"$regex\": \"Bell\"}})['user']['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#news_collection.delete_many({}) # delete all documents from collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More complicated query: 20 most popular hashtags\n",
    "\n",
    "What are the most popular hashtags in the dataset? \n",
    "    \n",
    "To start, let's find a document with at least one hashtag. Then we will build a pipeline using `aggregate`, which goes through a series of filtering sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_collection.find_one({\"entities.hashtags.0\": {\"$exists\": 1}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregation steps used below. Note that `$` signs get used for operators or for existing column names (to distinguish them from normal strings):\n",
    "- `$match`: The standard query used in `find` that we have already seen\n",
    "- `$project`: pick the fields that will end up in the output (projected)\n",
    "- `$unwind`: Take a field that contains an array, and create a new record for each element in that array (see example); like a SQL `JOIN`\n",
    "- `$group`: This is like a SQL `GROUP BY`. Take a mandatory `_id` (which is what it groups by). Create new fields with aggegate function\n",
    "- `$sort: { sort_field : +1 ascending or -1 descending }`\n",
    "- `$limit`: the number of records to return. This can also be called on the resulting cursor.\n",
    "\n",
    "\n",
    "#### Unwind example\n",
    "\n",
    "If we have a document\n",
    "```javascript\n",
    "{\n",
    "   '_id': 123456789,\n",
    "   'field1': [1,2,3],\n",
    "   'field2': [5,6,7],\n",
    "   'field3': 'abba'\n",
    "}\n",
    "```\n",
    "after doing an `$unwind` on field 2 you would get three new documents:\n",
    "```javascript\n",
    "{\n",
    "   '_id': 123456789,\n",
    "   'field1': [1,2,3],\n",
    "   'field2': 5,\n",
    "   'field3': 'abba'\n",
    "},\n",
    "{\n",
    "   '_id': 123456789,\n",
    "   'field1': [1,2,3],\n",
    "   'field2': 6,\n",
    "   'field3': 'abba'\n",
    "},\n",
    "{\n",
    "   '_id': 123456789,\n",
    "   'field1': [1,2,3],\n",
    "   'field2': 7,\n",
    "   'field3': 'abba'\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/mongo_aggregation.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate is a pipeline, order matters\n",
    "cursor = news_collection.aggregate([\n",
    "    {'$match': {'entities.hashtags.0': {'$exists': 1}}},\n",
    "    {'$project': {'_id': 0, 'hashtags': '$entities.hashtags'}},\n",
    "    {'$unwind': '$hashtags'},\n",
    "    {'$group': {'_id': '$hashtags.text', 'count': {'$sum': 1}}},\n",
    "    {'$sort': {'count': -1}},\n",
    "    {'$limit': 20}\n",
    "])\n",
    "\n",
    "list(cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real streaming: the tweepy API\n",
    "\n",
    "Okay, but how about real streaming? That is, an object that sits there are \"listens\" for new tweets, and then processes them as they arrive?\n",
    "\n",
    "This uses a slightly different API. There are a couple of things to pay attention to\n",
    "- The tweets that we get are *strings* of JSON objects, not the JSON objects themselves. We also don't have the nice ways of accessing the attributes directly (e.g. tweet.text above). Instead we convert the string to JSON, which gives us a dictionary, and then go from there.\n",
    "- A twitter stream takes a `StreamListener` class. We should write member functions `on_data` and `on_error` that are called when a new tweet arrives, or we encounter an error, respectively.\n",
    "\n",
    "In this example, we implement a `deque` of length 5, so that we are retaining the 5 most recent tweets. In the `on_data` call, we are adding the tweet to our collection, then printing out the currently stored tweets. \n",
    "\n",
    "If we wanted to store the data for all time, then `on_data` method would be where we would load them into Mongo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. RT @pollsofpolitics: What Approval percentage number would you give @POTUS @realDonaldTrump on the economy??\n",
      "\n",
      "Please vote and retweet to sp‚Ä¶\n",
      "\n",
      "\n",
      "1. RT @pollsofpolitics: Do you believe #VoterFraud is actually happening in #Florida??\n",
      "\n",
      "Please vote and retweet to spread poll for a wider sam‚Ä¶\n",
      "\n",
      "\n",
      "2. RT @JeferOficial: Buenos d√≠as mi amor ¬øC√≥mo amaneces? \n",
      "\n",
      "*Ya me voy a ba√±ar ¬øVienes?\n",
      "\n",
      "#MondayMotivation \n",
      "#GoPackGo https://t.co/Y4e0M7ToRg\n",
      "\n",
      "\n",
      "3. RT @SpectreKaiTM: When the media says ‚ÄúWhite nationalist‚Äù or ‚Äúracist‚Äù what they mean is ‚Äúa White person who hasn‚Äôt learned to hate themselv‚Ä¶\n",
      "\n",
      "\n",
      "4. RT @vashtiroebuck1: Happy Monday with some Cos D‚ÄôEstournel @RoebuckSteve1 @DrinkBordeaux @BordeauxWines @Bordeauxwinenew @cotes2bordeaux @V‚Ä¶\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWantReadError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSysCallError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/OpenSSL/SSL.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1714\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1715\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/OpenSSL/SSL.py\u001b[0m in \u001b[0;36m_raise_ssl_error\u001b[0;34m(self, ssl, result)\u001b[0m\n\u001b[1;32m   1520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_ERROR_WANT_READ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1521\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mWantReadError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1522\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_ERROR_WANT_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWantReadError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-55d136853ad8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mtwitter_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMyListener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mtwitter_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'#MondayMotivation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, follow, track, async, locations, stall_warnings, languages, encoding, filter_level)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'delimited'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'length'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'stream.twitter.com'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     def sitestream(self, follow, stall_warnings=False,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36m_start\u001b[0;34m(self, async)\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnooze_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnooze_time_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                 \u001b[0;31m# This is still necessary, as a SSLError can actually be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36m_read_loop\u001b[0;34m(self, resp)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# keep-alive new lines are expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36mread_line\u001b[0;34m(self, sep)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                     \u001b[0;31m# Close the connection when no data is returned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readinto_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_readinto_chunked\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                 \u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_chunk_left\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_get_chunk_left\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    544\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# toss the CRLF at the end of the chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                 \u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_next_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_read_next_chunk_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_next_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;31m# Read the next chunk size from the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chunk size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWantReadError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             \u001b[0mrd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The read operation timed out'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/urllib3/util/wait.py\u001b[0m in \u001b[0;36mwait_for_read\u001b[0;34m(socks, timeout)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mor\u001b[0m \u001b[0moptionally\u001b[0m \u001b[0ma\u001b[0m \u001b[0msingle\u001b[0m \u001b[0msocket\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     sockets that can be read from immediately. \"\"\"\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wait_for_io_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEVENT_READ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/urllib3/util/wait.py\u001b[0m in \u001b[0;36m_wait_for_io_events\u001b[0;34m(socks, events, timeout)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         return [key[0].fileobj for key in\n\u001b[0;32m---> 26\u001b[0;31m                 selector.select(timeout) if key[1] & events]\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/urllib3/util/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             kevent_list = _syscall_wrapper(self._kqueue.control, True,\n\u001b[0;32m--> 513\u001b[0;31m                                            None, max_events, timeout)\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkevent_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/urllib3/util/selectors.py\u001b[0m in \u001b[0;36m_syscall_wrapper\u001b[0;34m(func, _, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         and recalculate their timeouts. \"\"\"\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0merrcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "from IPython import display\n",
    "from collections import deque\n",
    "import json\n",
    "\n",
    "class MyListener(StreamListener):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.list_of_tweets = deque([], maxlen=5)\n",
    "        \n",
    "    def on_data(self, data):\n",
    "        tweet_text = json.loads(data)['text']\n",
    "        self.list_of_tweets.append(tweet_text)\n",
    "        self.print_list_of_tweets()\n",
    "        \n",
    "    \n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "\n",
    "    def print_list_of_tweets(self):\n",
    "        display.clear_output(wait=True)\n",
    "        for index, tweet_text in enumerate(self.list_of_tweets):\n",
    "            m='{}. {}\\n\\n'.format(index, tweet_text)\n",
    "            print(m)\n",
    "            \n",
    "twitter_stream = Stream(auth, MyListener())\n",
    "twitter_stream.filter(track=['#MondayMotivation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
